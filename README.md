# python-web-scraping

Note : This repository is under construction üõ†Ô∏è‚ö†Ô∏è

Hands-on workshop material on Web scraping using Python.

### To build and run site locally :

1. git clone https://github.com/MonashDataFluency/python-web-scraping.git
2. cd python-web-scraping
3. virtualenv -p python3 venv
4. source venv/bin/activate
5. pip install -r requirements.txt
6. mkdocs serve

Note : wptools might throw an error during installtion, in which case install other depencies as : 
- sudo apt install libcurl4-openssl-dev libssl-dev  

and then proceed to install wptools (via step 5 above)

Note: run `jupyter nbconvert --output-dir='markdowns/' --to markdown notebooks/*.ipynb` from the root directory to generate the markdowns from notebooks.

### TODO: 
## General:
- [x] Rename the files
- [x] Compile and build the website
- [x] githook for auto compile and build
- [x] As many images (with brief explantions within) as possible : (LucidChart,  Google draw)
- [x] Add a Reference section
- [x] Archive the website 
- [ ] Fix the issue of broken image in site
- [ ] Add challenges
- [ ] Add References

## Section 0
- [x] Complete the DF and regex section (pythex website)
- [x] Move the variable argument section to advanced topics
- [x] Add more text/explanations


## Section 1
- [x] Add more about html in text and add an image
- [x] Give more description in the image
- [x] Add json section -- added in section 0
- [x] DOM inspector
- [x] Long term: Add images/flowchart for better explanation 
 
## Section 2 
- [x] Shorten/Format the big html chunk
- [x] Prettify the output of html
- [x] Put more details on get/put requests (possibly visually)

## Section 3
- [ ] Add more explanations

## Section 4
- [ ] Add more explanations

## Section 5
- [ ] Add MCQs - Scenario based legal/grey questions
